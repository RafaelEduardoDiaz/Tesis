\documentclass[a4paper]{article}
\usepackage[left=2.5cm,top=3cm,bottom=3.5cm,right=2.5cm]{geometry} % Ajustar Margenes
\usepackage[spanish, es-tabla, es-nodecimaldot]{babel} % para producir la letras acentuadas "?"
\usepackage[utf8]{inputenc} % ecribir acentos ?
\usepackage{booktabs} % Para crear tablas
\usepackage{graphicx} % Para manipular imagenes 
\usepackage{amsmath} % Para el manejo de ecuaciones
\usepackage{color} % Para los colores
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=blue}
\title{Resultados} % Agregar titulo
\author{Rafael Eduardo Diaz} % Agregar Nombre

\setlength{\abovecaptionskip}{2pt plus 1pt minus 0pt} % Chosen fairly arbitrarily

<<echo=FALSE>>=
opts_chunk$set(background = "#e8e8e8", tidy = TRUE,echo = FALSE, message = FALSE, warning = FALSE)
@
\begin{document}

\maketitle
\section{Aplicación}

A continuación, ilustramos todos los modelos descritos anteriormente aplicándolos a dos conjuntos de datos, para la serie anual del número de homicidios en Colombia de 1960 a 2018 se ajustaron varios PHMM, mientras que para la serie mensual de incendios forestales en Colombia, entre el 2002 y 2016 se ajustaron diversos ZIP-HMM. Antes de que se ajusten los modelos, se llevo a cabo un análisis exploratorio básico del conjunto de datos que aborda algunos problemas que generalmente se presentan al visualizar los datos de conteo. Al final de la sección, se comparan todos los modelos ajustados, tanto desde el enfoque clásico como Bayesiano, y se selecciona el mejor modelo a partir de las dos metodologías. 

\vspace{5mm} %5mm vertical space

Para ambas series, la aplicación de modelos estándar como modelos auto regresivos de media móvil (ARMA) sería inapropiado, ya que estos modelos se basan en la distribución normal. En cambio, se propone un modelo usual para datos con conteos la distribución de Poisson, pero, como se demostrará más adelante, las series presenta una sobredispersión considerable con respecto a la distribución de Poisson, y fuerte dependencia serial positiva además de inflación en ceros en el caso de la serie de incendios. Por lo tanto, un modelo que consiste en variables aleatorias independientes de Poisson; sería por dos razones inadecuado. Primero que puede haber algunos períodos con una baja tasa de homicidios e incendios, y algunos con una tasa relativamente alta. Los HMMs, permiten que la distribución de probabilidad de cada observación dependa del estado no observado (u oculto) de una cadena de Markov, por lo tanto puede acomodar la sobredispersión y la dependencia serial al mismo tiempo.

<<echo=FALSE, include=FALSE>>=
library(xtable)
library(tibble)
library(stargazer)
library(scales)
library(Bayeshmmcts)
library(broom)
library(bayesplot)
library(rstan)
library(bridgesampling)
options(mc.cores = 4)
@

\subsection{Descripción de los datos}

\textbf{Homicidios:} Esta tabla contiene las cifras actualizadas de homicidios en Colombia 1960-2018, con base en la Compilación de estadísticas históricas económicas y sociales, extraída del \href{https://www.dnp.gov.co/estudios-y-publicaciones/estudios-economicos/Paginas/estadisticas-historicas-de-colombia.aspx}{departamento Nacional de Planeación} (DNP) se consulto específicamente el capítulo 8 indicadores de violencia, se complemento junto con las estadísticas delectivas de la \href{https://www.policia.gov.co/grupo-información-criminalidad/estadistica-delictiva}{Policía Nacional} y Medicina Legal. Los datos publicados corresponden a consolidados de los Delitos de Impacto del país, así mismo la Actividad Operativa realizada por la Policía Nacional. Mientras que para la población total Colombiana se extrajo la información de la sección Estadísticas por tema, demografía y población. La serie es anual para un total de 59 observaciones y se expresa como el número de homicidios por cada 100.000 habitantes comunmente conocida como \emph{Tasa de homicidios}, para ser posible la modelación se redondeo la cifra al entero más cercano. Nota: La confiabilidad de los datos de la tasa de asesinatos puede variar, de acuerdo a la fuente.

<<results='asis', echo=FALSE>>=
data("homicides")
homicidios <- homicides
colnames(homicidios) <- c("Año","Homicidios","Población","Tasa")
Homicidios <- ts(data = round(homicidios$Tasa), start = 1960)
df1 <- rbind(Homicidios[1:20],Homicidios[21:40],Homicidios[41:60])
print(xtable(df1,caption = "Número de homicidios por 100.000 habitantes en Colombia, 1960 - 2018.", digits = 0), include.colnames = FALSE, include.rownames = FALSE)
@

\vspace{5mm} %5mm vertical space

\textbf{Incendios:} Los datos referentes a incendios forestales en Colombia, fueron recolectados de la página del IDEAM - Instituto de Hidrología, Meteorología y Estudios Ambientales que ha venido realizando una revisión histórica y consolidado de los datos reportados por las siguientes instituciones: entidades del SINA, entidades del Sistema Nacional para la Prevención y atención de Desastres, la Defensa Civil, entre otras, y aunque se ha adoptado un Formulario Único de Captura (MAVDT \& otros, 2002), con el fin de estandarizar la información, este no ha sido utilizado en su totalidad y existen otros formatos desarrollados por las distintas entidades, de acuerdo con sus particularidades técnicas e informáticas, lo que ha dificultado la estandarización en el flujo de información.
\\
Las estadísticas sobre incendios en Colombia, permiten en términos generales, realizar análisis de su comportamiento bajo diferentes escenarios, esto es, por regiones, departamentos o municipios, con Niño o en condiciones climáticas normales,  por cobertura vegetal afectada, por Corporación Autónoma Regional, por año o por mes, y de esta manera, poder ser  utilizarlas para priorizar áreas, orientar acciones o sustentar la necesidad de realizar estudios más detallados. El Ideam ha venido realizando una revisión histórica de los datos reportados por las instituciones anteriormente mencionadas, con el fin de tener datos más confiables que permitan tener una mejor aproximación al tema. La variable de interés es el número de grandes incendios forestales (GIF), y se definen como aquellos incendios que superan las 500 hectáreas forestales afectadas. El número de observaciones es mensual iniciando en enero del 2002 y finalizando en diciembre del 2016, para un total 180 observaciones.

<<echo=FALSE, include=FALSE>>=
data("wildfires")
incendios <- wildfires
colnames(incendios) <- c("Fecha","GIF")
GIF <- ts(data = incendios$GIF, start = c(2002,1), frequency = 12)
nom <- c("Ene","Feb","Mar","Abr","May","Jun","Jul","Ago","Sep","Oct","Nov","Dic")
trace(.preformat.ts, quote(month.abb <- nom), print = FALSE)
@

<<echo=FALSE, results='asis'>>=
xtable(GIF, caption = "Número de Grandes Incendios Forestales (GIF) en Colombia, 2002 - 2016.")
@

\subsubsection*{Estadísticas de resumen}

A continuación se muestran algunas estadísticas descriptivas, sobre la serie de homicidios Colombia para los años 1960-2018.

<<echo=FALSE, results='asis'>>=
stargazer(data.frame(homicidios[,c(2,4)]), header = F,median = T, mean.sd = T, title = "Estadísticas de Resumen serie homicidios en Colombia.")
@

En la tabla el número mínimo de homicidios ocurrido en este período fue de 3908 con una Tasa de 19.26 homicidios por cada 100.000 habitantes, que corresponde al año 1969, mientras que el máximo número de homicidios registrados fue de 28.837 en el año 2002, sin embargo la Tasa más alta de homicidios fue en el año 1991 con casi 78 homicidios por cada 100.000 la más alta de la región para esta época según un estudio que presentó la CEPAL encontró que la tasa promedio homicidios en Latino-américa era de 20 por cada 100.000 habitantes. Algunas investigaciones sobre el tema como la de Franco (2006) y Pécaut (2003) han enfatizado ciertos aspectos coyunturales, tales como el problema del narcotráfico, la persistencia del conflicto armado interno, la debilidad del Estado, la corrupción y la inmadurez en el ejercicio de la ciudadanía pero aun son insuficientes los estudios y poco el consenso sobre las explicaciones de fondo de la situación de violencia que vive el país
\\
En el conjunto de los países con conflictos armados en el mundo, Colombia presenta uno de los más altos índices de homicidio40/100.000 en estas últimas seis décadas, con cifras comparables a las de países con guerra civil declarada. (Franco, 1980).

<<fig.width=6, fig.height=4, fig.cap="Serie de tiempo homicidios en Colombia desde el año 1960 hasta el año 2018.">>=
par(mar=c(2,2,1,.5)+.5, mgp=c(1.6,.6,0))
plot(Homicidios,xlab="Año",type='o', col=4, ylab = "Número")
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
lines(Homicidios, type='o', col=4)
@

En la figura 2, se encuentra gráficada la densidad de la serie Tasa de homicidios por 100.000 habitantes en Colombia, se deduce que utilizar modelo de regresión Poisson, sería inapropiado pues parece haber una mixtura entre dos distribuciones, ahora la pregunta que deberíamos hacernos es si estas dos distribuciones están correlacionadas, pues de no estarlo una opción para modelar esta serie sería utilizar una mixtura entre dos o más distribuciones independientes, como se muestra en Zucchini (2012, capítulo 1). Por otra parte parece haber una sobredispersión enorme pues mientras la media se sitúa en 40, la varianza es 292 es decir 7 veces la media, y recordemos que para la distribución Poisson $\mu = \sigma^2 = \lambda$. 

Un primer período de incremento acelerado que va desde comienzos de los 80, en particular desde 1983, hasta 1991. Es la fase más crítica de violencia, en particular de violencia homicida, en los anales de la ciudad. Las tasas de homicidio en la ciudad llegaron a marcar la tendencia de la curva de homicidios a nivel nacional. Investigaciones anteriores \textbf{19-22} han tratado de explicar este incremento acelerado mediante la convergencia de los problemas acumulados de debilidad institucional, ausencias estatales, ciudadanía precaria, desempleo e inequidades crecientes, con la expansión del fenómeno del narcotráfico en la ciudad \textbf{23} y su confrontación armada estatal, con la intensificación de la presencia urbana del conflicto armado interno, en especial la actuación de las milicias afines a las organizaciones guerrilleras y la emergencia y acelerado desarrollo de organizaciones paramilitares \textbf{24,25}.

<<fig.width=6.3, fig.height=4.8, fig.cap="Kernel Densidad de homicidios en Colombia (1960-2018).">>=
d <- density(Homicidios)
plot(d, ylab = "Densidad", main = "")
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
polygon(d, col=alpha("cyan", 0.2))
@

En la figura 3 se observa la función de autocorrelación muestral para la serie Tasa de homicidios hasta el rezago 30, como se evidencia existe una fuerte dependencia serial en los datos por lo que seria inapropiado utilizar un modelo de mixturas independientes (distribución Poisson), como alternativa surge la utilización de los modelos ocultos de Markov, en este caso se utilizara un PHMM.

<<fig.width=6, fig.height=3.5, fig.cap="Función de autocorrelación muetral, para la serie de homicidios.">>=
par(mar=c(2,2,1,.5)+.5, mgp=c(1.3,.6,0))
acf(Homicidios, xlab="Rezago",main="", lag.max = 30)
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
par(new = T)
acf(Homicidios, xlab="",main="", lag.max = 30)
@

\subsubsection*{Ajuste clásico PHMM}

<<cache=TRUE>>=
mod1 <- pois.HMM.mle(x = Homicidios, m = 1, lambda0 = 40, stationary = TRUE)

mod2 <- pois.HMM.mle(x = Homicidios, m = 2,
                     lambda0 = c(30, 63), 
                     gamma0 = matrix(c(0.9, 0.1, 0.1, 0.9), 2, 2, byrow = TRUE), 
                     stationary = TRUE)

mod3 <- pois.HMM.mle(x = Homicidios, m = 3,
                     lambda0 = c(28, 40, 64), 
                     gamma0 = matrix(c(0.8, 0.1, 0.1, 0.1, 0.8, 0.1, 0.1, 0.1, 0.8), 3, 3, byrow = TRUE), 
                     stationary = TRUE)

mod4 <- pois.HMM.mle(x = Homicidios, m = 4,
                     lambda0 = c(14, 31, 43, 65), 
                     gamma0 = matrix(c(0.85, 0.05, 0.05, 0.05, 
                                       0.05, 0.85, 0.05, 0.05, 
                                       0.05, 0.05, 0.85, 0.05,
                                       0.05, 0.05, 0.05, 0.85), 4, 4, byrow = TRUE), 
                     stationary = TRUE)

mod5 <- pois.HMM.mle(x = Homicidios, m = 5,
                     lambda0 = c(7, 25, 36, 47, 70), 
                     gamma0 = matrix(c(0.80, 0.05, 0.05, 0.05, 0.05, 
                                       0.05, 0.80, 0.05, 0.05, 0.05, 
                                       0.05, 0.05, 0.80, 0.05, 0.05,
                                       0.05, 0.05, 0.05, 0.80, 0.05,
                                       0.05, 0.05, 0.05, 0.05, 0.080
                     ), 5, 5, byrow = TRUE), 
                     stationary = TRUE)
@

<<>>=
library(flexmix)
fmod2 <- flexmix(Homicidios~1, k = 2, model = FLXMRglm(family = "poisson"))
fmod3 <- flexmix(Homicidios~1, k = 3, model = FLXMRglm(family = "poisson"))
fmod4 <- flexmix(Homicidios~1, k = 4, model = FLXMRglm(family = "poisson"))
@

Primero ajustamos varios modelos Poisson ocultos de Markov con 1 a 5 estados, y tres modelos con mixturas independientes con 2, 3 y 4 componentes de la distribución Poisson utilizando el paquete \textbf{flexmix} de R. Por último registramos los siguientes valores en la Tabla 3, el número de parámetros estimados, la log-verosimilitud el criterio de información de Akaike (AIC) y el criterio de información bayesiano (BIC). Con el fin de seleccionar el modelo más apropiado, el valor que minimiza el AIC es el PHMM de orden 3 con un valor de 404.02, mientras que el BIC indica que el modelo apropiado es un PHMM de orden 2, con un valor de 418.96. Tanto el BIC y AIC resuelven este problema mediante la introducción de un término de penalización para el número de parámetros en el modelo, el término de penalización es mayor en el BIC que en el AIC. El BIC generalmente penaliza parámetros libres con más fuerza que hace el criterio de información de Akaike, aunque depende del tamaño de $n$ y la magnitud relativa de $n$ y $p$. Como el tamaño de la muestra es relativamente grande $n = 59$, y la cantidad de parámetros que se estiman en un HMM es bastante utilizaremos el BIC en este caso en concreto, eligiendo por tanto el PHMM de orden 2.

<<results='asis'>>=
Tabla1 <- data.frame(
  Modelo = c("PHMM - Estados 1", "PHMM - Estados 2", "PHMM - Estados 3", "PHMM - Estados 4", "PHMM - Estados 5", "mixtura indep. (2)", "mixtura indep. (3)", "mixtura indep. (4)"),
  p = c(1, 4, 9, 16, 25, 3, 5, 7),
  logL = c(mod1$mllk, mod2$mllk, mod3$mllk, mod4$mllk, mod5$mllk, -229.376, -228.106, -228.107),
  AIC = c(mod1$AIC, mod2$AIC, mod3$AIC, mod4$AIC, mod5$AIC, AIC(fmod2), AIC(fmod3), AIC(fmod4)),
  BIC = c(mod1$BIC, mod2$BIC, mod3$BIC, mod4$BIC, mod5$BIC, BIC(fmod2), BIC(fmod3), BIC(fmod4)))
xtable(Tabla1, caption = "Datos homicidios: comparación de modelos ocultos de Markov (estacionarios) por AIC y BIC.")
@

<<fig.height=4.8, fig.cap="Serie homicidios: selección de modelos AIC y BIC.", fig.pos='h'>>=
plot(x = 1:5, y = Tabla1$AIC[1:5], type = "o", pch = 16, lty = 2, xlim = c(1,6), xlab = "Número de estados", ylab = "")
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
lines(x = 1:5, y = Tabla1$AIC[1:5], type = "o", pch = 16, lty = 2)
lines(x = 1:5, y = Tabla1$BIC[1:5], type = "o", pch = 16, lty = 2)
text(x = c(5.3,5.3), y = c(435, 485), labels = c("AIC","BIC"))
@

Varios comentarios surgen de la Tabla 4. En primer lugar, dada la dependencia en serie manifestada en la Figura 2, no es sorprendente que los modelos de mezcla independientes no tengan un buen desempeño en relación con los HMM. En segundo lugar, aunque quizás sea obvio a priori que ni siquiera se debe intentar establecer un modelo con un máximo de 16 o 25 parámetros para 59 observaciones, y observaciones dependientes, es interesante explorar las funciones de verosimilitud en el caso de HMM con cuatro y cinco estados. La verosimilitud parece ser altamente multimodal en estos casos, y es fácil encontrar varios máximos locales utilizando diferentes valores de inicio. Una estrategia que parece tener éxito en estos casos es comenzar todas las probabilidades de transición fuera de la diagonal en valores pequeños (como 0.1 o 0.05), mientras que para los valores de las medias estado dependientes se pueden usar los valores de los deciles, calculados a partir de la variable de interés.

<<results='asis',eval=FALSE>>=
M <- mod2$gamma
Tab=xtable(M,align=rep("",ncol(M)+1), digits = 3) # We repeat empty string 6 times
print(Tab, floating=FALSE, tabular.environment="pmatrix",hline.after=NULL, 
      include.rownames=FALSE, include.colnames=FALSE)
@

La estimaciones del PHMM de dos estados se muestran a continuación, primero la tpm $A$, además del vector de medias de los estados dependientes $\lambda$ y los valores de la distribución estacionaria $\pi$. 

$$
A = \begin{pmatrix}{}
  0.980 & 0.020 \\ 
  0.064 & 0.936 \\ 
\end{pmatrix}
$$

$$\lambda = (29.715, 62.812) \ \ \ \ \pi = (0.764, 0.235)$$

Ahora miraremos otras metodologías alternativas a los criterios de información AIC y BIC, que determinan si el modelo tiene un buen ajuste. Entre estas es útil comparar las funciones de autocorrelación de los HMM con dos, tres, cuatro y cinco estados con la función de autocorrelación muestral (ACF). Los ACF de los modelos se pueden encontrar utilizando la función `Bayeshmmcts::pois.HMM.moments` utilizando la ecuación de Zucchini, pág. 55. En forma tabular los ACF se muestran en la tabla 5:

<<results='asis'>>=
ACFHMM <- data.frame(
       round(rbind(acf(Homicidios, plot = FALSE, lag.max = 12)$acf[-1],
              pois.HMM.moments(mod2, lag.max = 12)$rho,
              pois.HMM.moments(mod3, lag.max = 12)$rho,
              pois.HMM.moments(mod4, lag.max = 12)$rho),3))
rownames(ACFHMM) <- c("observaciones","PHMM 2 Estados","PHMM 3 Estados","PHMM 4 Estados")
colnames(ACFHMM) <- 1:12
xtable(ACFHMM, caption = "Datos homicidios: ACF y ACF de los cuatro modelos hasta el rezago 12.")
@

<<fig.height=4.1, fig.cap="Datos homicidios: ACF y ACF de los PHMM con dos y tres estados.", fig.pos='h'>>=
plot(x = 0:12, y = acf(Homicidios, plot = FALSE, lag.max = 12)$acf, ylab = "", type = "h", col = 1,xlab="Rezago",xaxt="n")
axis(1, at = 0:12)
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
lines(x = 0:12, y = acf(Homicidios, plot = FALSE, lag.max = 12)$acf, type = "h", col = 1)
lines(x = 0:12+0.1, y = c(1,pois.HMM.moments(mod2, lag.max = 12)$rho), type = "h", col = 3)
lines(x = 0:12+0.2, y = c(1,pois.HMM.moments(mod3, lag.max = 12)$rho), type = "h", col = 4)
abline(h = 0)
@

En la Figura 6, de izquierda a derecha se muestran el ACF de las observaciones, la barra de color verde pertenece al modelo de dos estados y la azul al modelo de tres estados. Nos interesa ver como está yuxtapuesto los ACF de ambos modelos con respecto al ACF de las observaciones. Está claro que los ACF del modelo con tres estados corresponden bien con el ACF de las observaciones hasta aproximadamente el rezago 6, mientras que el modelo 2 estados coincide hasta el rezago 9. Sin embargo, se pueden aplicar diagnósticos más sistemáticos, como se mostrará a continuación.

\subsubsection*{Verificación de supuestos del PHMM}

En este caso hemos elegido el BIC como criterio para la selección del mejor modelo como mostramos anteriormente, sin embargo sigue existiendo el problema de decidir si el modelo es realmente adecuado; por lo tanto se necesitan herramientas para evaluar la bondad general del ajuste del modelo e identificar valores atípicos en relación con el modelo. En el contexto más simple como por ejemplo los modelos de regresión (teoría normal), el papel que juegan los residuales como herramienta para la verificación del supuesto del modelo está muy bien establecido, entre estos supuestos están la normalidad de los residuales, la homocedasticidad y la independencia de estos. Los pseudo-residuos (también conocidos como residuos quantílicos) que se ilustraron en la sección tres tienen la intención de cumplir esta función de manera mucho más general, y que son útiles en el contexto de los HMM. 

<<fig.cap="Grafico pseudo-residuales ordinarios para el PHMM de 2 estados.", fig.pos='h', fig.height=6.3>>=
residuales <- pois.HMM.pseudo_residuals(x = Homicidios, mod = mod2)
pois.HMM.plot.residuals(residuales)
@

En el gráfico 6, se muestra los pseudo residuales ordinarios del PHMM con 2 estados. La fila superior izquierda muestra el diagramas de índice de los pseudo-residuos normales, con líneas horizontales en 0, $\pm 1.96$ y $\pm 2.58$. En la parte superior derecha se muestra los gráficos de cuantiles-cuantiles de los pseudo-residuos normales, con los cuantiles teóricos en el eje $x$. La última fila muestra en la parte izquierda el histograma de los pseudo residuales normales, y en la parte derecha la función de autocorrelación muestral de los pseudo-residuos normales. Efectivamente los pseudo-residuales parecen distribuirse normalmente, sin embargo realizamos la prueba de Shapiro-Wilks para verificar este supuesto, donde el p-valor es 0.7529, por lo tanto no podemos rechazar la hipótesis nula $H_0$, y concluimos que hay suficiente evidencia estadística para decir que los pseudo-residuos se distribuyen normalmente con un nivel de confianza del 95\%. Además todos los puntos están dentro de las bandas de confianza, sin embargo el histograma no parece acomodarse en todos sus puntos a la curva de la distribución normal, y el mayor problema es que los pseudo-residuales parecen estar correlacionados, hasta el rezago 3.

\subsubsection*{Algoritmo Viterbi}

El algoritmo Viterbi, permite realizar la decodificación global de los estados clasificando a cada una de las observaciones en su correspondiente estado, indicando la secuencia más probable de los estados ocultos. Para la serie homicidios de 59 observaciones, el algoritmo Viterbi clasifico 40 observaciones en el estado 1 y 19 en el estado 2. En la grafica 5 se visualiza el algoritmo viterbi, y las distribuciones marginales para cada estado.
\\
La decodificación global (algoritmo Viterbi) es el objetivo principal en muchas aplicaciones, especialmente cuando existen interpretaciones importantes para los estados. Sin embargo los estados no observados en el modelo, no siemprre necesitan tener interpretaciones sustantiva, pues se consideran artefactos útiles para adaptarse a la heterogeneidad no explicada y la dependencia serial de los datos. En el caso de la serie homicidios no parce haber una interpretación clara de los estados.

<<results='asis'>>=
viterbi2 <- pois.HMM.viterbi(x = Homicidios, mod = mod2)
df2 <- rbind(viterbi2[1:20], viterbi2[21:40], viterbi2[41:60])
print(xtable(df2, caption = "Resultados de la decodificación global con el algoritmo Viterbi.", digits = 0), include.colnames = FALSE, include.rownames = FALSE)
@

<<fig.width=8, fig.height=4, fig.cap="Algoritmo Viterbi aplicado a un PHMM de dos estados.">>=
par(mfrow = c(1,2))
par(mar=c(2,2,1,.5)+.5, mgp=c(1.6,.6,0))
### Plot 1
plot(Homicidios,xlab="Año",type='o', col=4, ylab = "Número")
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
lines(Homicidios, type='o', col=4)
abline(h = mod2$lambda, col = "chartreuse2", lty = 2)
points(x = homicidios[,1], y = ifelse(viterbi2 == 1, mod2$lambda[1], mod2$lambda[2]), pch = 21, bg =  "chartreuse2", col = "white")
### Plot 2
delta <- pois.HMM.stadist(mod2)
xf <- 5:95
dstat <- numeric(length(xf))
for(j in 1:mod2$m) dstat <- dstat + delta[j] * dpois(xf, mod2$lambda[j])

dstat1 <- numeric(length(xf))
dstat2 <- numeric(length(xf))

dstat1 <- delta[1] * dpois(xf, mod2$lambda[1])
dstat2 <- delta[2] * dpois(xf, mod2$lambda[2])

hist(Homicidios, probability = T,ylim = c(0,0.06), xlim = c(5,95), col = "grey", border = "white", breaks = 20, ylab = "", xlab = "", main = "")
par(new = TRUE)
plot(xf, dstat, type = "l", ylim = c(0,0.06),xlim = c(5,95), lwd = 2, ylab = "", xlab = "")
lines(xf, dstat1, col = "red", lwd = 2)
lines(xf, dstat2, col = "blue", lwd = 2)
lines(x = mod2$lambda, y = c(max(dstat1), max(dstat2)), type = "h", col = c("red", "blue"), lwd = 2, lty = 2)
@

<<fig.cap="Pronostico de la distribución para los años 2019 a 2034.", fig.height=9.5>>=
#=== Forecast 1-4 steps ahead and plot these .
h <- 16
xf <- 5:75
`año` <- homicidios[,1]
forecasts <- pois.HMM.forecast(xf, h, Homicidios, mod2)
par(mfrow = c(4, 4), las = 1)
for(i in 1:h){
  fc <- forecasts[, i]
  plot(xf, fc, type = "h", main = paste("Dist. pronós.", `año`[59] + i), 
       xlim = c(5, max(xf+2)), ylim = c(0 ,0.1), cex.main = 0.85,
       xlab = "conteo", ylab = "probabilidad", lwd = 1)
  rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
  lines(xf, fc, type = "h", lwd = 1)
  dstat <- numeric(length(xf))
  for(j in 1:mod2$m) dstat <- dstat + delta[j] * dpois(xf, mod2$lambda[j])
  lines(xf, dstat, col = "chartreuse2", lwd = 2)
  }
@

Se realiza la predicción de los estados más probables para los proximos 16 años, tambien podemos pronosticar la distribución para estos mismos años. Como se observa en la figura 8 a medida que el horizonte de pronóstico $h$ aumenta, la distribución de pronóstico converge a la distribución marginal del HMM estacionario. En la tabla 7, se observa que el prónstico de los estados, para los próximos 16 años es el 1, es decir que se espera una tasa de homidios por cada 100.000 habitantes cercana a 29, la cual sigue siendo alta ya que según datos de la ONUDD (Oficina de Naciones Unidas contra la Droga y el Delito), en sur America la tasa se situa en 20/100.000 homicidios, lo que indica quee la tasa de homicidios en  Colombia está por encima de la región. Además según estadísticas de la ONUDD, Colombia se situa como uno de los países más violentos del mundo ubicandose en el top 20, las cifras de la fiscalia indican que despues de haber disminuido la tasa de homidios en los últimos años, a partir del 2018 hubo un incremento del $3.25 \%$, de este delito siendo caso críticos las ciudades de Medellín, bajo Cauca y Tumaco, mientras la capital sigue con tendencia a la baja.

<<results='asis'>>=
Estad_pred <- data.frame(`Año`=`año`[59]+1:16,pois.HMM.state_prediction(h=16,x=Homicidios,mod=mod2))
colnames(Estad_pred) <- c("Año","Estado 1","Estado 2")
Estad_pred$Estado <- apply(Estad_pred, 1, which.max)
print(xtable(Estad_pred, caption = "Predicción para las probabilidades de los estados hasta un rezago h = 16.", digits = 4), include.rownames = FALSE)
@

En el siguiente aparto se muestran las estimaciones bayesianas realizadas a la serie homicidios

%http://www.scielo.br/pdf/csc/v17n12/06.pdf

\clearpage

\subsubsection*{Estimación Bayesiana del PHMM}

<<eval=FALSE>>=
# Modelo de 2 estados - 9.60 seg
system.time(
PHMM_2states <- bayes.PHMM(y = Homicidios, m = 2, chains = 3, iter = 1000, control = list(adapt_delta = 0.99)))

# Modelo de 3 estados - 33.97
system.time(
PHMM_3states <- bayes.PHMM(y = Homicidios, m = 3, chains = 3, iter = 1000, control = list(adapt_delta = 0.99)))

# Modelo de 4 estados - 252.90
system.time(
PHMM_4states <- bayes.PHMM(y = Homicidios, m = 4, chains = 3, iter = 1000, control = list(adapt_delta = 0.9999, max_treedepth = 15)))

# Modelo de 5 estados - 1943.18
system.time(
PHMM_5states <- bayes.PHMM(y = Homicidios, m = 5, chains = 3, iter = 1000, control = list(adapt_delta = 0.9999, max_treedepth = 15)))
@

<<eval=FALSE>>=
library(bridgesampling)
# estimates of the log marginal likelihoods
set.seed(1)                                         #   loglm       lp     mllk
bridge_H0 <- bridge_sampler(samples = PHMM_2states) # -211.69  -210.58  -201.32
bridge_H1 <- bridge_sampler(samples = PHMM_3states) # -212.89  -219.31  -193.00
bridge_H2 <- bridge_sampler(samples = PHMM_4states) # -219.54  -240.80  -190.84
bridge_H3 <- bridge_sampler(samples = PHMM_5states)

error_measures(bridge_H0)$percentage #"0.616%"
error_measures(bridge_H1)$percentage #"2.76%"
error_measures(bridge_H2)$percentage #"27.2%"
error_measures(bridge_H3)$percentage #"31.9%"
#The Bayes factor in favor of H0 over H1 can then be obtained as follows:
bf(bridge_H0, bridge_H1) # A favor de H0 3.36230
bf(bridge_H0, bridge_H2) # fuertemente a favor de H0 2545.85
bf(bridge_H0, bridge_H3) # fuertemente a favor de H0 390147608.97574

bf(bridge_H1, bridge_H2) # fuertemente a favor de H1 766.05
bf(bridge_H1, bridge_H3) # fuertemente a favor de H1 125542040.73572

bf(bridge_H2, bridge_H3) # fuertemente a favor de H2 128023.60921
@

Primero se ajustaron cuatro modelos, con la función `Bayeshmmcts::bayes.PHMM`, para 2, 3, 4 y 5 estados, después, se estimo la $\log$ - verosimilitud marginal, utilizando muestreo por puente como alternativa a las propuesta hecha por Newton y Raftery (1994) que sugiere utilizar la verosimilitud integrada, para hallar el estimador de la media armónica de los valores de la verosimilitud de una muestra obtenida desde la distribución posterior. Pero como se vio en la sección (4), aunque el estimador es consitente tiene un gran problema varianza infinita. Mientras que el estimador del muestreador por puente, no presenta ese problema además de su facil implementación, pues esta metodología se puede ejecutar con la función `bridge sampler` del paquete bridgesampling, del autor Gronau. El paquete \textbf{bridgesampling}, permite además calcular el error de la estimación para la verosimilitud marginal, obtendido via muestreo por puente que en el caso del modelo con dos estados, el error es de $0.478 \%$. 

Un factor de Bayes es la relación entre la probabilidad de una hipótesis particular y la probabilidad de otra. Puede interpretarse como una medida de la fuerza de la evidencia en favor de una teoría entre dos teorías en competencia. Esto se debe a que el factor de Bayes nos permite evaluar los datos a favor de una hipótesis nula y utilzar información externa para hacerlo. Nos dice cuál es el peso de la evidencia a favor de una hipótesis dada.

Cuando estamos comparando dos hipótesis, $H_0$ (la hipótesis nula) y $H_1$ (la hipótesis alternativa) y , el factor de Bayes a menudo se escribe como $B_{01}$. Se puede definir matemáticamente como

$$B_{01} = \frac{\text{verosimilitud de los datos dado $H_0$}}{\text{verosimilitud de los datos dado $H_1$}} = \frac{P(D | H_0)}{P(D | H_1)}$$

El factor de Bayes puede es un número positivo, y una de las interpretaciones más comunes es esta: propuesta por primera vez por Harold Jeffereys(1961) y modificada ligeramente por Lee y Wagenmakers en 2013:

<<results='asis'>>=
print(xtable(
data.frame(B01 = c(">100","30 - 100","10 - 30","3 - 10","1 - 3","1","1/3 - 1","1/10 - 1/3","1/30 - 1/3","1/100 - 1/30","< 1/100"), `Desición` =c("Evidencia extrema para H0","Evidencia muy fuerte para H0","Evidencia fuerte para H0","Evidencia moderada para H0","Evidencia apenas mencionable para H0","No hay evidencia","Evidencia apenas mencionable para H1","Evidencia moderada para H1","Evidencia fuerte para H1","Evidencia muy fuerte para H1","Evidencia extrema para H1")), caption = "Interpretación del factor de Bayes, Lee y Wagenmakers (2013)."),include.rownames = FALSE)
@

Ahora utilizamos el factor de bayes para contrastar los modelos con m-estados de a parejas, y seleccionar el más adecuado, en la siguiente tabla ilustra el contraste de hipótesis, donde las filas indican $P(D | H_0)$ y las columnas $P(D | H_1)$. Por ejemplo en el contraste de hipótesis entre el modelo de 3 estados vs el modelo de 4 estados, el valor obtenido fue $B_{01} = 766.05$, lo que indica evidencia extrema para $H_0$, es decir el modelo de 3 estados es más apropiado que el de 4 estados.

<<results='asis'>>=
FactorBayes <- data.frame("mod 2 Estados" = c(NA, 3.36230, 2545.85, 390147608),
                          "mod 3 Estados" = c(NA, NA, 766.05361, 125542040),
                          "mod 4 Estados" = c(NA, NA, NA, 128023), check.names = F)
rownames(FactorBayes) <- c("mod 2 Estados", "mod 3 Estados", "mod 4 Estados", "mod 5 Estados")
xtable(t(FactorBayes), caption = "Comparación resultados Factor de Bayes.")
@

<<include=FALSE, cache=TRUE>>=
system.time(
PHMM_2states <- bayes.PHMM(y = Homicidios, m = 2, chains = 3, iter = 5000, thin = 3, 
                            control = list(adapt_delta = 0.8), seed = 7))  # 8.74 seg
set.seed(3)
bridge_H0 <- bridge_sampler(samples = PHMM_2states)
error_measures(bridge_H0)
@

De la tabla 9, se concluye que el modelo apropiado es el de orden 2, lo cual coincide con el BIC. Se corrieron 5.000 iteraciones con 3 cadenas y las primeras 2.500 iteraciones de calentamiento adelgazando la cadena cada 3 iteraciones; con tasa de aceptación para la función objetivo en el metropolis de 0.99. A continuación mostramos las estimaciones bayesianas de la matriz de transición, y la media de los estados dependiesntes:

<<results='asis'>>=
resumenPHMM <- as.data.frame(summary(PHMM_2states)$summary)
A_bayes <- matrix(resumenPHMM$mean[1:4], 2,2)
lambda_bayes <- resumenPHMM$mean[5:6]
colnames(resumenPHMM) <- c("Media","Err.Sta","Desv","2.5%","25%","50%","75%","97.5%","n_eff","Rhat")
rownames(resumenPHMM) <- c("$\\Gamma_{11}$","$\\Gamma_{12}$","$\\Gamma_{21}$","$\\Gamma_{22}$","$\\lambda_1$","$\\lambda_2$","lp")
print(xtable(resumenPHMM, caption = "Estimación bayesiana de los parámetros para un PHMM.", digits = 3), sanitize.rownames.function = function(x) {x})
@

<<results='asis'>>=
source("Bayes_fun.R")
B_viterbi <- bayes.viterbi(x = Homicidios, model = PHMM_2states, m = 2)
# bayes.lforward(x = Homicidios, model = PHMM_2states, m = 2)
df3 <- rbind(B_viterbi[1:20], B_viterbi[21:40], B_viterbi[41:60])
print(xtable(df3, caption = "Resultados de la decodificación global bayesiana con el algoritmo Viterbi.", digits = 0), include.colnames = FALSE, include.rownames = FALSE)
@

<<fig.width=8, fig.height=4, fig.cap="Algoritmo Viterbi aplicado a un PHMM de dos estados.">>=
par(mfrow = c(1,2))
par(mar=c(2,2,1,.5)+.5, mgp=c(1.6,.6,0))
### Plot 1
plot(Homicidios,xlab="Año",type='o', col=4, ylab = "Número")
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
lines(Homicidios, type='o', col=4)
abline(h = lambda_bayes, col = "orange", lty = 2)
points(x = homicidios[,1], y = ifelse(B_viterbi == 1, lambda_bayes[1], lambda_bayes[2]), pch = 21, bg = "orange", col = "white")
### Plot 2
delta_bayes <- bayes.stadist(model = PHMM_2states, m = 2)
xf <- 5:95
dstatB <- numeric(length(xf))
for(j in 1:2) dstatB <- dstatB + delta_bayes[j] * dpois(xf, lambda_bayes[j])

dstatB1 <- numeric(length(xf))
dstatB2 <- numeric(length(xf))

dstatB1 <- delta_bayes[1] * dpois(xf, lambda_bayes[1])
dstatB2 <- delta_bayes[2] * dpois(xf, lambda_bayes[2])

hist(Homicidios, probability = T,ylim = c(0,0.06), xlim = c(5,95), col = "grey", border = "white", breaks = 20, ylab = "", xlab = "", main = "")
par(new = TRUE)
plot(xf, dstatB, type = "l", ylim = c(0,0.06),xlim = c(5,95), lwd = 2, ylab = "", xlab = "")
lines(xf, dstatB1, col = "violetred", lwd = 2)
lines(xf, dstatB2, col = "forestgreen", lwd = 2)
lines(x = lambda_bayes, y = c(max(dstatB1), max(dstatB2)), type = "h", col = c("violetred", "forestgreen"), lwd = 2, lty = 2)
@

<<results='asis'>>=
B_state_pred <- as.data.frame(bayes.state_prediction(h = 12, x = Homicidios, model = PHMM_2states,m = 2))
colnames(B_state_pred) <- c("Estado 1","Estado 2")
rownames(B_state_pred) <- `año`[59]+1:12
B_state_pred$Estado <- apply(B_state_pred, 1, which.max)
xtable(B_state_pred, caption = "Predicción bayesiana para las probabilidades de los estados hasta un rezago h = 12.", digits = 4)
@

\subsubsection*{Diagnosticos de la cadena}

En esta sección se verificara el diagnostico de convergencia de las cadenas utilizadas en la extracción de las muestras. Para los métodos MCMC ajustados con \textbf{Stan}, ya sean Hamiltonian Monte (HMC) o No-U-Turn-Sampler (NUTS), el paquete \emph{bayesplot} y \emph{coda}, cuenta con una serie de herrmientas gráficas y purebas diagnosticas para después del ajuste de modelos bayesianos. En la figura No se muestra los histogramas univariados y diagramas de dispersión bivariados para los parámetros de la matriz de transición de probabilidad y para el vector de medias de los estados dependientes, especialmente útil para identificar la colinealidad entre variables (que se manifiesta como gráficos bivariados estrechos), así como la presencia de no-identificabilidad multiplicativa (formas tipo plátano).

En sentido estricto, la no identificabilidad significa que dos valores de los parámetros dan como resultado la misma distribución de probabilidad de los datos observados. Algunas veces también se usa para cubrir situaciones en las que no hay un máximo local único de la densidad posterior, ya sea porque hay múltiples máximos separados o porque hay una meseta donde un conjunto de puntos tiene la misma densidad posterior (estos pueden o pueden No ser identificable en sentido estricto).

En este caso parece no haber problemas con la identificabilidad, es decir que no existen problemas que señalan divergencias, lo único que se observa es colinealidad entre los parámetros de las filas de la matriz de transición, sin embargo recordemos por definición que la suma de las filas de la tpm suman 1, por lo tanto están de por si correlacionadas. Por lo tanto como el modelo es identificable, no estamos asegurando que las inferencias no están sesgadas.

<<fig.cap="Gráfico de dispersión para las muestras MCMC.">>=
# Extract posterior draws for later use
posterior <- as.array(PHMM_2states)
lp_cp <- log_posterior(PHMM_2states)
np_cp <- nuts_params(PHMM_2states)
color_scheme_set("mix-brightblue-gray")
mcmc_pairs(posterior, np = np_cp, pars = c("Gamma[1,1]","Gamma[1,2]","Gamma[2,1]","Gamma[2,2]",
                                           "lambda[1]","lambda[2]"), off_diag_args = list(size = 0.75))
@

El gráfico de traza, muestra por cada una de las iteraciones los valores muestreados correspondiente a una o más cadenas de Markov, separado por parámetro. Las cadenas proporcionan una forma visual para inspeccionar el comportamiento de muestreo y evaluar la mezcla a través de las cadenas y la convergencia, como vemos se comportana bastante bien, pues hay un mínimo de muestras divergentes.

<<fig.height=5, fig.cap="Gráfico de trazas de las cadenas, para cada iteración y por cadena.">>=
rstan::traceplot(PHMM_2states)
@
                              
Los intervalos de credibilidad, para los parámetros calculados a partir de las muestras posteriores con todas las cadenas fusionadas. Índican valores consistentes en las estimaciones de los parámetros.

<<fig.width=6, fig.height=3.3, fig.cap="Intervalos de crédibilidad.">>=
library(gridExtra)
color_scheme_set("red")
p1 <- mcmc_intervals(posterior, pars = c("Gamma[1,1]", "Gamma[1,2]", "Gamma[2,1]", "Gamma[2,2]"))
p2 <- mcmc_intervals(posterior, pars = c("lambda[1]", "lambda[2]"))
grid.arrange(p1, p2, ncol = 2)
@

La prueba de convergencia utiliza la estadística de Cramer-von-Mises para probar la hipótesis nula de que los valores muestreados provienen de una distribución estacionaria. La prueba se aplica sucesivamente, primero a toda la cadena, luego, después de descartar el primer $10 \%$, $20 \%$, ... de la cadena hasta que se acepte la hipótesis nula, o se haya descartado el $50 \%$ de la cadena. El último resultado constituye un \emph{fallo} de la prueba de estacionariedad e indica que se necesita una ejecución MCMC más larga. Si se pasa la prueba de estacionariedad, se informa el número de iteraciones a mantener y el número a descartar.

La prueba de medio ancho calcula un intervalo de confianza del $95 \%$ para la media, utilizando la parte de la cadena que pasó la prueba de estacionariedad. La mitad del ancho de este intervalo se compara con la estimación de la media. Si la relación entre la mitad del ancho y la media es menor que \emph{eps}, se pasa la prueba de la mitad del ancho. De lo contrario, la longitud de la muestra no se considera lo suficientemente larga como para estimar la media con suficiente precisión.

<<results='asis'>>=
library(coda)
PHMM_mcmc <- as.mcmc(as.matrix(PHMM_2states))
Test_HyW <- heidel.diag(PHMM_mcmc)
# Tabla 1
Heidel1 <- data.frame(`P. Estacionariedad` = rep("páso",7), `Valor p` = c(0.396, 0.978, 0.396, 0.978, 0.569, 0.862, 0.440), check.names = F)
# Tabla 2
Heidel2 <- data.frame(`P. Medio ancho`= rep("páso",7), Media = c(0.9526, 0.0994, 0.0474, 0.9006, 29.7014, 62.7417, -210.5250), `Valor p` = c(0.00139, 0.00250, 0.00139, 0.00250, 0.03430, 0.07890, 0.06213))
Heidel <- cbind(Heidel1, Heidel2)
rownames(Heidel) <- c("$\\Gamma_{11}$","$\\Gamma_{21}$", "$\\Gamma_{12}$", "$\\Gamma_{22}$", "$\\lambda_1$", "$\\lambda_2$", "lp")

print(xtable(Heidel, caption = "Prueba de estacionariedad, usando el estadístico de Cramer-von-Mises para la convergencia de la cadena y prueba de medio ancho para la media calculando el intervalo de confianza al 0.95.", type = "latex", digits = 3), sanitize.text.function = function(x){x})
@

\subsubsection{Comparación PHMM clásico vs Bayesiano}

La inferencia para los parámetros bajo el enfoque clásico se realizo utilizando bootstrap (Zucchini (2016)). El método bootstrap es una técnicas de remuestreo diseñadas para aproximar la función de distribución de probabilidad de los datos mediante una función empírica de una muestra finita. El método bootstrap se puede usar para estimar los intervalos de confianza directamente. Se utilizo el ``método de percentil" (Efron y Tibshirani, 1993) para estimar los intervalos, se generaron 250 muestras independientes a partir del PHMM de orden 2 de longitud 59 igual a la serie homicidios en Colombia. Los valores iniciales usados fueron los estimados por PHMM de 2 estados con el fin de evitar inestabilidad numérica o problemas de convergencia. Los intervalos de credibilidad fueron calculados a partir de las distribuciones aposteriori de los parámetros de las muestras generadas por MCMC. El nivel y la probabilidad de los intervalos de confianza y credibilidad, respectivamente, se fijaron en 0.95.

<<eval=FALSE>>=
#round(HPDinterval(PHMM_mcmc, 0.95),5)
intervalos_cred <- as.data.frame(mcmc_intervals_data(posterior, prob_outer = 0.95, point_est = "mean"))[,c(5,7,9)]
intervalos_cred$Ancho <- intervalos_cred$hh - intervalos_cred$ll
intervalos_cred <- intervalos_cred[,c(2,1,3:4)]
system.time(intervalos_conf <- pois.HMM.confint(mod = mod2, n = 59, B = 250)) # 28 seg
rownames(intervalos_cred) <- c(rownames(intervalos_conf),"lp__")
Inter <- cbind(Parámetros = rownames(intervalos_conf), intervalos_cred[-7,],intervalos_conf)
colnames(Inter) <- colnames(Inter) <- c("Parámetros","Intervalos de Credibilidad__Media","Intervalos de Credibilidad__2.5","Intervalos de Credibilidad__97.5","Intervalos de Credibilidad__Ancho","Intervalos de Confianza__Media","Intervalos de Confianza__2.5","Intervalos de Confianza__97.5","Intervalos de Confianza__Ancho")
rownames(Inter) <- 1:nrow(Inter)
#xtable(Inter, digits = 4, caption = "Intervalos de Credibilidad y Confianza fijados al 0.95.")
dput(Inter)
@

<<results='asis'>>=
Inter <- structure(list(`Parámetros` = structure(c(1L, 3L, 2L, 4L, 5L, 6L
), .Label = c("gamma11", "gamma12", "gamma21", "gamma22", "lambda1", 
"lambda2"), class = "factor"), `Intervalos de Credibilidad__Media` = c(0.953306305245798, 
0.0988650895931146, 0.0466936947542024, 0.901134910406885, 29.7146461795756, 
62.848881470366), `Intervalos de Credibilidad__2.5` = c(0.8730943032276, 
0.0137328284845021, 0.00644181146650225, 0.742764299683423, 28.0974843512562, 
59.0680219574867), `Intervalos de Credibilidad__97.5` = c(0.993558188533498, 
0.257235700316577, 0.1269056967724, 0.986267171515498, 31.4600097828223, 
66.7345814746465), `Intervalos de Credibilidad__Ancho` = c(0.120463885305898, 
0.243502871832075, 0.120463885305898, 0.243502871832075, 3.36252543156606, 
7.66655951715981), `Intervalos de Confianza__EMV` = c(0.98024196466361, 
0.063967950749355, 0.01975803533639, 0.936032049250645, 29.7159253816026, 
62.8126152684851), `Intervalos de Confianza__2.5` = c(0.844180217176474, 
0.01536203142682, 1.28184117164957e-13, 1.25124093299868e-05, 
27.6886806238408, 30.1401054496543), `Intervalos de Confianza__97.5` = c(0.999999999999872, 
0.99998748759067, 0.155819782823526, 0.98463796857318, 31.647902636959, 
68.4966722513429), `Intervalos de Confianza__Ancho` = c(0.155819782823398, 
0.98462545616385, 0.155819782823398, 0.98462545616385, 3.95922201311823, 
38.3565668016886)), class = "data.frame", row.names = c(NA, 6L
))

library(grattanCharts)
print_2heading_xtable(Inter, separator = "__", xtable.dots = list(caption = "Intervalos de Credibilidad y Confianza para el PHMM de orden 2.", digits = 3))
@

Al calcular los intervalos de confianza y de credibilidad, es importante determinar cuál de estos métodos son más eficaces. Para determinar el comportamiento de los intervalos propuestos, usualmente se utiliza, la longitud del intervalo, su probabilidad de cobertura el valor esperado y la varianza de su longitud. Un buen método debe tener valores pequeños en la longitud del intervalo, en su valor esperado y en la varianza de su longitud; con probabilidades de cobertura cercanas a los niveles de confianza nominal.
\\
La longitud del intervalo, que indica su precisión, se muestran en la tabla 14, junto con la media de las estimaciones en el caso Bayesiano y el estimador de máxima verosimilitu para el caso clásico. Tanto para los parámetros de la matriz de transición como para el vector de medias de los estados dependientes, los intervalos de credibilidad indican una longitud menor es decir mayor precisión.

\clearpage

\subsection{Modelo Poisson Cero inflado - Oculto de Markov}

<<>>=
rm(list = ls())
library(Bayeshmmcts)
library(ziphsmm)
data("wildfires")
incendios <- wildfires
colnames(incendios) <- c("Fecha", "GIF")
GIF <- ts(data = incendios$GIF, start = c(2002,1), frequency = 12)
@

En esta sección utilizaremos, los datos de incendios forestales en Colombia, desde enero del 2001 hasta diciembre del 2016. La variable de interés es el número de grandes incendios forestales (GIF), que son aquellos incendios que superan las 500 hectáreas forestales afectadas. La periodicidad de los datos es mensual con un total 180 observaciones, en la Tabla 11 se muestran los primeros 12 registros, mientras que la Tabla 12 indica la frecuencia. Allí observamos que hay una alta proporción de ceros en los datos, pues de las 180 observaciones 124 son cero, es decir el $68.9 \%$ de los registros. Por otra parte el número máximo de GIF ocurridos en un mes en Colombia fue 23 en febrero del 2017, lo cual es preocupante; pues aunque los incendios forestales naturales han ocurrido desde siempre como un elemento normal en el funcionamiento de los ecosistemas. El fuego ha permitido la regeneración de diversos ecosistemas y la producción de una serie de hábitats en los que distintos organismos pueden prosperar. No obstante notemos que el promedio de GIF se ubico en $1.3 \pm 3.5$ incendio por mes, haciendo que la enorme proliferación de los incendios a causa de la actividad humana en estas últimas décadas sobrepasa la capacidad de recuperación natural.

<<fig.width=5.8, fig.height=4, fig.cap="Serie de tiempo Grandes Incendios Forestales en Colombia desde el año 2002 hasta el año 2016.", fig.pos='h'>>=
par(mar=c(2,2,1,.5)+.5, mgp=c(1.6,.6,0), mfrow = c(1,1))
plot(GIF, xlab="Año", type='o', col=4, ylab = "Número", xaxt="n")
axis(1, at = 2002:2016, las=1)
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
lines(GIF, type='o', col=4)
@

En la figura 13, se observa dos picos altos en el 2007 y el 2010. Después del año 2011 la cero inflación disminuye considerablemente y el número de incendios en gran parte de los meses parece estar por encima de 5, este fenómeno se presenta de manera recurrente en gran parte del país, en especial durante los periodos secos prolongados, durante los cuales los ecosistemas tropicales húmedos y muy húmedos pierden parte de los contenidos de humedad superficial e interior, incrementando sus niveles de susceptibilidad y amenaza hacia la combustión de la biomasa vegetal que los compone. En la tabla 2 sse encuentran todos los datos de GIF en Colombia-
\\
Para determinar si existe correlación entre los GIF de cada mes, se calcula la función de autocorrelación muestral, la figura 14 indica no solo la existencia de la dependencia serial sino una estructura estacional

<<fig.width=6, fig.height=3.5, fig.cap="Función de autocorrelación muetral, para la serie GIF.">>=
par(mar=c(2,2,1,.5)+.5, mgp=c(1.3,.6,0), mfrow = c(1,1))
acf(GIF, xlab="Rezago",main="", lag.max = 80)
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
par(new = T)
acf(GIF, xlab="",main="", lag.max = 80)
@

Como se vio en la figura 14, existe dependencia serial entre los GIF mensuales ocurridos de Colombia, además parece haber una estructura estacional entre los meses donde ocurrieron estos incendios. 

<<fig.width=6.3, fig.height=4.8, fig.cap="Kernel Densidad serie Grandes Incendios Forestales en Colombia (2002-2016).">>=
d <- density(GIF)
plot(d, ylab = "Densidad", main = "")
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
polygon(d, col=alpha("red", 0.4))
@

\subsubsection{Ajuste del ZIP-HMM}

<<include=FALSE, cache=TRUE>>=
ZIPHMM_2states <- hmmfit(y=incendios$GIF,
                         M = 2, prior_init = c(0.6, 0.4),
                         tpm_init = matrix(c(0.9,0.1,
                                             0.5,0.5),2,2,byrow=TRUE),
                         emit_init=c(7, 45), zero_init = c(0.4,0),
                         method="Nelder-Mead",hessian=TRUE,control=list(maxit=1000,trace=1))

ZIPHMM_3states <- hmmfit(y=incendios$GIF,
                         M = 3, prior_init = c(0.5,0.2,0.3),
                         tpm_init = matrix(c(0.8,0.15,0.05,
                                             0.45,0.4,0.15,
                                             0.2,0.35,0.45),3,3,byrow=TRUE),
                         emit_init=c(3, 17, 54), zero_init = c(0.45,0,0),
                         method="Nelder-Mead",hessian=TRUE,control=list(maxit=1000,trace=1))

ZIPHMM_4states <- hmmfit(y=incendios$GIF,
                         M = 4, prior_init = c(0.5,0.2,0.2,0.1),
                         tpm_init = matrix(c(0.80,0.15,0.04,0.01,
                                             0.50,0.30,0.15,0.05,
                                             0.15,0.35,0.45,0.05,
                                             0.15,0.35,0.25,0.25),4,4,byrow=TRUE),
                         emit_init=c(3, 15, 43, 100), zero_init = c(0.45,0,0,0),
                         method="Nelder-Mead",hessian=TRUE,control=list(maxit=1000,trace=1))

ZIPHMM_5states <- hmmfit(y=incendios$GIF,
                         M = 5, prior_init = c(1,1,1,1,1)/5,
                         tpm_init = matrix(c(0.75,0.15,0.05,0.025,0.025,
                                             0.35,0.30,0.25,0.05,0.05,
                                             0.35,0.20,0.20,0.20,0.05,
                                             0.15,0.20,0.25,0.35,0.05,
                                             0.10,0.20,0.25,0.20,0.25),5,5,byrow=TRUE),
                         emit_init=c(2.5, 11, 25, 49, 100), zero_init = c(0.45,0,0,0,0),
                         method="Nelder-Mead",hessian=TRUE,control=list(maxit=1000,trace=1))

ZIPHMM_6states <- hmmfit(y=incendios$GIF,
                         M = 6, prior_init = c(1,1,1,1,1,1)/6,
                         tpm_init = matrix(c(0.75,0.15,0.05,0.02,0.02,0.01,
                                             0.15,0.40,0.25,0.10,0.05,0.05,
                                             0.45,0.05,0.20,0.20,0.05,0.05,
                                             0.15,0.15,0.30,0.15,0.20,0.05,
                                             0.10,0.10,0.20,0.20,0.25,0.15,
                                             0.10,0.10,0.25,0.20,0.15,0.20),6,6,byrow=TRUE),
                         emit_init=c(2, 6, 15, 31, 51, 100), zero_init = c(0.48,0,0,0,0,0),
                         method="Nelder-Mead",hessian=TRUE,control=list(maxit=1000,trace=1))

ZIPHMM_7states <- hmmfit(y=incendios$GIF,
                         M = 7, prior_init = c(1,1,1,1,1,1,1)/7,
                         tpm_init = matrix(c(0.70,0.10,0.05,0.05,0.020,0.04,0.04,
                                             0.25,0.30,0.20,0.10,0.050,0.05,0.05,
                                             0.30,0.10,0.15,0.20,0.150,0.05,0.05,
                                             0.30,0.10,0.10,0.175,0.175,0.05,0.10,
                                             0.10,0.10,0.15,0.20,0.15,0.20,0.10,
                                             0.10,0.15,0.15,0.15,0.15,0.25,0.05,
                                             0.10,0.10,0.15,0.15,0.20,0.10,0.20),7,7,byrow=TRUE),
                         emit_init=c(1.5, 4.5, 11, 17, 32, 52, 99), zero_init = c(0.48,0,0,0,0,0,0),
                         method="Nelder-Mead",hessian=TRUE,control=list(maxit=1000,trace=1))
@

<<results='asis'>>=
Tabla2 <- data.frame(
  Modelo = c("ZIPHMM - Estados 2", "ZIPHMM - Estados 3", "ZIPHMM - Estados 4", "ZIPHMM - Estados 5","ZIPHMM - Estados 6","ZIPHMM - Estados 7"),
  p = c(6, 12, 20, 30, 42, 56),
  logL = c(ZIPHMM_2states$nllk, ZIPHMM_3states$nllk, ZIPHMM_4states$nllk, ZIPHMM_5states$nllk, ZIPHMM_6states$nllk, ZIPHMM_7states$nllk),
  AIC = c(ZIPHMM_2states$aic, ZIPHMM_3states$aic, ZIPHMM_4states$aic, ZIPHMM_5states$aic, ZIPHMM_6states$aic, ZIPHMM_7states$aic),
  BIC = c(ZIPHMM_2states$bic, ZIPHMM_3states$bic, ZIPHMM_4states$bic, ZIPHMM_5states$bic, ZIPHMM_6states$bic, ZIPHMM_7states$bic))
xtable(Tabla2, caption = "Datos incendios: comparación de modelos ocultos de Markov (Cero inflados) por AIC y BIC.")
@

<<fig.height=4.8, fig.cap="Serie incendios: selección de modelos AIC y BIC.", fig.pos='h'>>=
plot(x = 2:7, y = Tabla2$AIC, type = "o", pch = 16, lty=2,xlim=c(1.5,7.5), ylim=c(1000,1600), xlab = "Número de estados", ylab = "")
rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1,col='white')
lines(x = 2:7, y = Tabla2$AIC, type = "o", pch = 16, lty = 2)
lines(x = 2:7, y = Tabla2$BIC, type = "o", pch = 16, lty = 2)
text(x = c(7.2,7.2), y = c(1135, 1317), labels = c("AIC","BIC"))
# AIC 6 estados y BIC 4 estados
@

<<>>=
ZIP.viterbi <- hmmviterbi(y = incendios$GIF, 
           ntimes = length(incendios$GIF), 
           M = 4, prior_init = ZIPHMM_4states$prior, 
           tpm_init = ZIPHMM_4states$tpm, 
           emit_init = ZIPHMM_4states$emit_parm, 
           zero_init = ZIPHMM_4states$zeroprop)
@

<<fig.width=8, fig.height=4, fig.cap="Algoritmo Viterbi aplicado al ZIPHMM de tres estados.">>=
par(mfrow = c(1,1))
par(mar=c(2,2,1,.5)+.5, mgp=c(1.6,.6,0))
### Plot 1
plot(GIF,xlab="Año",type='o', col=4, ylab = "Número")
rect(par("usr")[1], par("usr")[3],par("usr")[2],par("usr")[4],col=gray(.9,.9),border='white');grid(lty=1, col='white')
lines(GIF, type='o', col=4)
abline(h = ZIPHMM_4states$emit_parm, col = "orange", lty = 2)
points(x = time(GIF), y = ifelse(ZIP.viterbi == 1, ZIPHMM_4states$emit_parm[1],
                                 ifelse(ZIP.viterbi == 2, ZIPHMM_4states$emit_parm[2],
                                        ifelse(ZIP.viterbi == 3,ZIPHMM_4states$emit_parm[3],
                                               ZIPHMM_4states$emit_parm[4]))), pch = 21, bg = "orange", col = "white")
@

<<eval=FALSE>>=
system.time(Bayes_ZIPHMM1_2S <- bayes.ZIPHMM1(y=GIF,m=2,chains=4,iter=2000))#38.90
system.time(Bayes_ZIPHMM1_3S <- bayes.ZIPHMM1(y=GIF,m=3,chains=4,iter=2000))#44.23
system.time(Bayes_ZIPHMM1_4S <- bayes.ZIPHMM1(y=GIF,m=4,chains=4,iter=2000))#60.88
system.time(Bayes_ZIPHMM1_5S <- bayes.ZIPHMM1(y=GIF,m=5,chains=4,iter=2000,control=list(adapt_delta=0.99)))#600.85
system.time(Bayes_ZIPHMM1_6S <- bayes.ZIPHMM1(y=GIF,m=6,chains=4,iter=2000,control=list(adapt_delta=0.99)))#968.67
system.time(Bayes_ZIPHMM1_7S <- bayes.ZIPHMM1(y=GIF,m=7,chains=4,iter=2000,control=list(adapt_delta=0.99, max_treedepth = 15)))#808.83
@

<<eval=FALSE>>=
library(bridgesampling)
# estimates of the log marginal likelihoods
set.seed(1)
bridge_H0 <- bridge_sampler(samples = Bayes_ZIPHMM1_2S)
bridge_H1 <- bridge_sampler(samples = Bayes_ZIPHMM1_3S)
bridge_H2 <- bridge_sampler(samples = Bayes_ZIPHMM1_4S)
bridge_H3 <- bridge_sampler(samples = Bayes_ZIPHMM1_5S)
bridge_H4 <- bridge_sampler(samples = Bayes_ZIPHMM1_6S)
bridge_H5 <- bridge_sampler(samples = Bayes_ZIPHMM1_7S)

error_measures(bridge_H0)$percentage #"0.224%"
error_measures(bridge_H1)$percentage #"0.447%"
error_measures(bridge_H2)$percentage #"1.080%"
error_measures(bridge_H3)$percentage #"5.350%"
error_measures(bridge_H4)$percentage #"3.260%"
error_measures(bridge_H5)$percentage #"25.00%"

#The Bayes factor in favor of H0 over H1 can then be obtained as follows:
Tabla2          #     nllk    bridge Estados
bridge_H0$logml # 764.6139 -769.0118  2
bridge_H1$logml # 592.8111 -603.9224  3
bridge_H2$logml # 536.0731 -557.4197  4
bridge_H3$logml # 521.8713 -553.6015  5
bridge_H4$logml # 508.6004 -557.9988  6
bridge_H5$logml # 510.7902 -571.662   7

bf(bridge_H0, bridge_H1) # Evidencia extrema para H1 0.00000
bf(bridge_H0, bridge_H2) # Evidencia extrema para H2 0.00000
bf(bridge_H0, bridge_H3) # Evidencia extrema para H3 0.00000
bf(bridge_H0, bridge_H4) # Evidencia extrema para H4 0.00000
bf(bridge_H0, bridge_H5) # Evidencia extrema para H5 0.00000

bf(bridge_H1, bridge_H2) # Evidencia extrema para H2 0.00000
bf(bridge_H1, bridge_H3) # Evidencia extrema para H3 0.00000
bf(bridge_H1, bridge_H4) # Evidencia extrema para H4 0.00000
bf(bridge_H1, bridge_H5) # Evidencia extrema para H5 0.00000

bf(bridge_H2, bridge_H3) # Evidencia muy fuerte para H3 0.02197 modelo 5 estados
bf(bridge_H2, bridge_H4) # Apenas mencionable para H2 1.78455
bf(bridge_H2, bridge_H5) # Eviencia extrema para H2 1513518

bf(bridge_H3, bridge_H4) # Evidencia muy fuerte para H3 81.22963
bf(bridge_H3, bridge_H5) # Evidencia muy fuerte para H3 84986740

bf(bridge_H4, bridge_H5) # Evidencia muy fuerte para H4 956226
# Nos quedamos con H3 5 estados
@


<<echo=FALSE, cache=TRUE, include=FALSE>>=
Bayes_ZIPHMM1_4S <- bayes.ZIPHMM1(y=GIF,m=4,chains=3,iter=2000, seed = 7)
@

<<results='asis'>>=
resumenZIP_HMM <- as.data.frame(summary(Bayes_ZIPHMM1_4S)$summary)
A_Zbayes <- matrix(resumenZIP_HMM$mean[6:21], 4,4)
lambda_Zbayes <- resumenZIP_HMM$mean[2:5]
theta_Zbayes <- resumenZIP_HMM$mean[1]
colnames(resumenZIP_HMM) <- c("Media","Err.Sta","Desv","2.5%","25%","50%","75%","97.5%","n_eff","Rhat")
rownames(resumenZIP_HMM) <- c("$\\theta$","$\\lambda_1$","$\\lambda_2$","$\\lambda_3$","$\\lambda_4$","$\\Gamma_{11}$","$\\Gamma_{12}$","$\\Gamma_{13}$","$\\Gamma_{14}$","$\\Gamma_{21}$","$\\Gamma_{22}$","$\\Gamma_{23}$","$\\Gamma_{24}$","$\\Gamma_{31}$","$\\Gamma_{32}$","$\\Gamma_{33}$","$\\Gamma_{34}$","$\\Gamma_{41}$","$\\Gamma_{42}$","$\\Gamma_{43}$","$\\Gamma_{44}$","lp")
print(xtable(resumenZIP_HMM, caption = "Estimación bayesiana de los parámetros para un ZIPH-MM.", digits = 3), sanitize.rownames.function = function(x) {x})
@

\section{Anexo Códigos}

A continuación se anexa el código utilizado para el desarrollo de esta tesis, en la aplicación del PHMM a la base homicidios en Colombia y el ajuste del ZIP-HMM a los Grandes Incendios Forestales (GIF) en Colombia. 

\clearpage

<<eval=FALSE, echo=TRUE>>=

################
### Packages ###
################
library(Bayeshmmcts)
library(broom)


################
##### Data #####
################
data("homicidios")
data("incendios")

#################################
# Poisson - Hidden Markov Model #
#################################

###############################################
# Zero Inflated Poisson - Hidden Markov Model #
###############################################

@



\end{document}